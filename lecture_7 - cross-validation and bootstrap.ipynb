{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c347bad8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from ISLP import load_data\n",
    "import statsmodels.api as sm\n",
    "\n",
    "from ISLP.models import (ModelSpec as MS, summarize, poly)\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fd92102b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "from sklearn.model_selection import (cross_validate, KFold, ShuffleSplit)\n",
    "from sklearn.base import clone\n",
    "from ISLP.models import sklearn_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "98cf8ce5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d69b103",
   "metadata": {},
   "source": [
    "### validation set approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "67cbe7ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(392, 8)\n"
     ]
    }
   ],
   "source": [
    "Auto = load_data('Auto')\n",
    "print(Auto.shape)\n",
    "# As there are 392 observations, we split into two equal sets of size 196\n",
    "Auto_train, Auto_valid = train_test_split(Auto, test_size=196, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0738c78a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "const    39.905465\n",
       "x1       -0.156307\n",
       "dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = Auto_train['horsepower'].values\n",
    "X_train = sm.add_constant(X_train)\n",
    "y_train = Auto_train['mpg']\n",
    "model = sm.OLS(y_train, X_train)\n",
    "results = model.fit()\n",
    "results.params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5809cdf7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>           <td>mpg</td>       <th>  R-squared:         </th> <td>   0.608</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.606</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   300.4</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Sun, 16 Feb 2025</td> <th>  Prob (F-statistic):</th> <td>2.83e-41</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>22:48:51</td>     <th>  Log-Likelihood:    </th> <td> -590.83</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>   196</td>      <th>  AIC:               </th> <td>   1186.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>   194</td>      <th>  BIC:               </th> <td>   1192.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     1</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "    <td></td>       <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th> <td>   39.9055</td> <td>    1.009</td> <td>   39.537</td> <td> 0.000</td> <td>   37.915</td> <td>   41.896</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x1</th>    <td>   -0.1563</td> <td>    0.009</td> <td>  -17.333</td> <td> 0.000</td> <td>   -0.174</td> <td>   -0.139</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td> 7.263</td> <th>  Durbin-Watson:     </th> <td>   2.175</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.026</td> <th>  Jarque-Bera (JB):  </th> <td>   6.993</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 0.440</td> <th>  Prob(JB):          </th> <td>  0.0303</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 3.286</td> <th>  Cond. No.          </th> <td>    319.</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/latex": [
       "\\begin{center}\n",
       "\\begin{tabular}{lclc}\n",
       "\\toprule\n",
       "\\textbf{Dep. Variable:}    &       mpg        & \\textbf{  R-squared:         } &     0.608   \\\\\n",
       "\\textbf{Model:}            &       OLS        & \\textbf{  Adj. R-squared:    } &     0.606   \\\\\n",
       "\\textbf{Method:}           &  Least Squares   & \\textbf{  F-statistic:       } &     300.4   \\\\\n",
       "\\textbf{Date:}             & Sun, 16 Feb 2025 & \\textbf{  Prob (F-statistic):} &  2.83e-41   \\\\\n",
       "\\textbf{Time:}             &     22:48:51     & \\textbf{  Log-Likelihood:    } &   -590.83   \\\\\n",
       "\\textbf{No. Observations:} &         196      & \\textbf{  AIC:               } &     1186.   \\\\\n",
       "\\textbf{Df Residuals:}     &         194      & \\textbf{  BIC:               } &     1192.   \\\\\n",
       "\\textbf{Df Model:}         &           1      & \\textbf{                     } &             \\\\\n",
       "\\textbf{Covariance Type:}  &    nonrobust     & \\textbf{                     } &             \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lcccccc}\n",
       "               & \\textbf{coef} & \\textbf{std err} & \\textbf{t} & \\textbf{P$> |$t$|$} & \\textbf{[0.025} & \\textbf{0.975]}  \\\\\n",
       "\\midrule\n",
       "\\textbf{const} &      39.9055  &        1.009     &    39.537  &         0.000        &       37.915    &       41.896     \\\\\n",
       "\\textbf{x1}    &      -0.1563  &        0.009     &   -17.333  &         0.000        &       -0.174    &       -0.139     \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lclc}\n",
       "\\textbf{Omnibus:}       &  7.263 & \\textbf{  Durbin-Watson:     } &    2.175  \\\\\n",
       "\\textbf{Prob(Omnibus):} &  0.026 & \\textbf{  Jarque-Bera (JB):  } &    6.993  \\\\\n",
       "\\textbf{Skew:}          &  0.440 & \\textbf{  Prob(JB):          } &   0.0303  \\\\\n",
       "\\textbf{Kurtosis:}      &  3.286 & \\textbf{  Cond. No.          } &     319.  \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "%\\caption{OLS Regression Results}\n",
       "\\end{center}\n",
       "\n",
       "Notes: \\newline\n",
       " [1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                    mpg   R-squared:                       0.608\n",
       "Model:                            OLS   Adj. R-squared:                  0.606\n",
       "Method:                 Least Squares   F-statistic:                     300.4\n",
       "Date:                Sun, 16 Feb 2025   Prob (F-statistic):           2.83e-41\n",
       "Time:                        22:48:51   Log-Likelihood:                -590.83\n",
       "No. Observations:                 196   AIC:                             1186.\n",
       "Df Residuals:                     194   BIC:                             1192.\n",
       "Df Model:                           1                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "const         39.9055      1.009     39.537      0.000      37.915      41.896\n",
       "x1            -0.1563      0.009    -17.333      0.000      -0.174      -0.139\n",
       "==============================================================================\n",
       "Omnibus:                        7.263   Durbin-Watson:                   2.175\n",
       "Prob(Omnibus):                  0.026   Jarque-Bera (JB):                6.993\n",
       "Skew:                           0.440   Prob(JB):                       0.0303\n",
       "Kurtosis:                       3.286   Cond. No.                         319.\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "33e90317",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23.61661706966988"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_valid = Auto_valid['horsepower'].values\n",
    "X_valid = sm.add_constant(X_valid)\n",
    "y_valid = Auto_valid['mpg']\n",
    "valid_pred = results.predict(X_valid)\n",
    "np.mean((y_valid - valid_pred)**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "53ada93b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# evalMSE() that takes a model string as well as a training and test set and returns the MSE on the test set\n",
    "def evalMSE(train, test, d):\n",
    "    X_train = train['horsepower']\n",
    "    X_train = np.power.outer(X_train.values, np.arange(d+1))\n",
    "    y_train = train['mpg']\n",
    "    \n",
    "    X_test = test['horsepower']\n",
    "    X_test = np.power.outer(X_test.values, np.arange(d+1))\n",
    "    y_test = test['mpg']\n",
    "    \n",
    "    results = sm.OLS(y_train, X_train).fit()\n",
    "    test_pred = results.predict(X_test)\n",
    "    return np.mean((y_test - test_pred)**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a8d3e81a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 1\n",
      "1 2\n",
      "2 3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([23.61661707, 18.76303135, 18.79694163])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MSE = np.zeros(3)\n",
    "\n",
    "for idx, degree in enumerate(range(1, 4)):\n",
    "    print(idx, degree)\n",
    "    MSE[idx] = evalMSE(Auto_train, Auto_valid, degree) \n",
    "\n",
    "MSE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee80486c",
   "metadata": {},
   "source": [
    "try a different training, validation split by setting a different random_state\n",
    "\n",
    "the mses are different"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f26a5115",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([20.75540796, 16.94510676, 16.97437833])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Auto_train, Auto_valid = train_test_split(Auto, test_size=196, random_state=3)\n",
    "\n",
    "MSE = np.zeros(3)\n",
    "for idx, degree in enumerate(range(1, 4)):\n",
    "    MSE[idx] = evalMSE(Auto_train, Auto_valid, degree) \n",
    "    \n",
    "MSE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b183f1bb",
   "metadata": {},
   "source": [
    "an **alternative** implementation of polynomial features\n",
    "\n",
    "use PolynomialFeatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "33ec34e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "92b4a2fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(196, 1)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Auto_train[['horsepower']].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "677a7f54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# evalMSE() that takes a model string as well as a training and test set and returns the MSE on the test set\n",
    "def evalMSE(train, test, d):\n",
    "    poly_features = PolynomialFeatures(degree=d)\n",
    "    X_train = poly_features.fit_transform(train[['horsepower']]) \n",
    "    y_train = train['mpg']\n",
    "    \n",
    "    X_test = poly_features.fit_transform(test[['horsepower']])\n",
    "    y_test = test['mpg']\n",
    "    \n",
    "    results = sm.OLS(y_train, X_train).fit()\n",
    "    test_pred = results.predict(X_test)\n",
    "    return np.mean((y_test - test_pred)**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "44d8819d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([20.75540796, 16.94510676, 16.97437833])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Auto_train, Auto_valid = train_test_split(Auto, test_size=196, random_state=3)\n",
    "MSE = np.zeros(3)\n",
    "for idx, degree in enumerate(range(1, 4)):\n",
    "    MSE[idx] = evalMSE(Auto_train, Auto_valid, degree) \n",
    "    \n",
    "MSE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14e6ed9b",
   "metadata": {},
   "source": [
    "### cross validation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc638425",
   "metadata": {},
   "source": [
    "LOOCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1a9996ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24.231513517929226"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "M = sklearn_sm(sm.OLS)\n",
    "H = np.array(Auto['horsepower'])\n",
    "X = sm.add_constant(H)\n",
    "Y = Auto['mpg']\n",
    "cv_results = cross_validate(M, X, Y, cv=Auto.shape[0])\n",
    "cv_err = np.mean(cv_results['test_score'])\n",
    "cv_err"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4226b0e",
   "metadata": {},
   "source": [
    "an alternative implementation of LOOCV without adding a constant term"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "805c244d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24.231513517929226"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# an intercept term is included\n",
    "hp_model = sklearn_sm(sm.OLS, MS(['horsepower']))\n",
    "X, Y = Auto.drop(columns=['mpg']), Auto['mpg']\n",
    "## cv = Auto.shape[0] is LOOCV\n",
    "cv_results = cross_validate(hp_model, X, Y, cv=Auto.shape[0])\n",
    "cv_err = np.mean(cv_results['test_score'])\n",
    "cv_err"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5923ece",
   "metadata": {},
   "source": [
    "LOOCV for polynomial regressions\n",
    "\n",
    "define the polynomials of horsepower using np.power.outer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fdbcd994",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(392, 2) 1\n",
      "(392, 3) 2\n",
      "(392, 4) 3\n",
      "(392, 5) 4\n",
      "(392, 6) 5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([24.23151352, 19.24821312, 19.33498406, 19.42443032, 19.03322078])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_error = np.zeros(5)\n",
    "H = np.array(Auto['horsepower'])\n",
    "# if terms are not specified in sklean_sm, then sm.OLS uses all the columns in X without including an intercept term\n",
    "M = sklearn_sm(sm.OLS)\n",
    "for i, d in enumerate(range(1,6)):\n",
    "    X = np.power.outer(H, np.arange(d+1))\n",
    "    print(X.shape, d)\n",
    "    M_CV = cross_validate(M, X, Y, cv=Auto.shape[0])\n",
    "    cv_error[i] = np.mean(M_CV['test_score'])\n",
    "cv_error"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55ab7ca4",
   "metadata": {},
   "source": [
    "K-fold cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2d4d22f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([24.20766449, 19.18533142, 19.27626666, 19.478484  , 19.1372021 ])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_error = np.zeros(5)\n",
    "H = np.array(Auto['horsepower'])\n",
    "\n",
    "cv = KFold(n_splits=10, shuffle=True, random_state=0) # use same splits for each degree\n",
    "\n",
    "for i, d in enumerate(range(1,6)):\n",
    "    X = np.power.outer(H, np.arange(d+1))\n",
    "    M_CV = cross_validate(M, X, Y, cv=cv)\n",
    "    cv_error[i] = np.mean(M_CV['test_score'])\n",
    "    \n",
    "cv_error"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b60b51d3",
   "metadata": {},
   "source": [
    "### bootstrap"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e611ce8",
   "metadata": {},
   "source": [
    "Estimating the Accuracy of a Statistic of Interest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e48fefae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.57583207459283"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Portfolio = load_data('Portfolio')\n",
    "\n",
    "def alpha_func(D, idx):\n",
    "    cov_ = np.cov(D[['X','Y']].loc[idx], rowvar=False)\n",
    "    return ((cov_[1,1] - cov_[0,1]) / (cov_[0,0]+cov_[1,1]-2*cov_[0,1]))\n",
    "\n",
    "alpha_func(Portfolio, range(100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b129be87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6074452469619002"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rng = np.random.default_rng(0)\n",
    "alpha_func(Portfolio, rng.choice(100, 100, replace=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f4f2cb64",
   "metadata": {},
   "outputs": [],
   "source": [
    "def boot_SE(func, D, n=None, B=1000, seed=0):\n",
    "    rng = np.random.default_rng(seed)\n",
    "    first_, second_ = 0, 0\n",
    "    n = n or D.shape[0]\n",
    "    for _ in range(B):\n",
    "        idx = rng.choice(D.index, n, replace=True)\n",
    "        value = func(D, idx)\n",
    "        first_ += value\n",
    "        second_ += value**2\n",
    "    return np.sqrt(second_ / B - (first_ / B)**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c58c110d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.09118176521277607"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alpha_SE = boot_SE(alpha_func, Portfolio, B=1000, seed=0)\n",
    "alpha_SE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdd560bc",
   "metadata": {},
   "source": [
    "Estimating the Accuracy of a Linear Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "51172efa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def boot_OLS(X, Y, B=1000, seed=0):\n",
    "    rng = np.random.default_rng(seed)\n",
    "    n = X.shape[0]\n",
    "    first_, second_ = np.zeros((2,)), np.zeros((2,))\n",
    "    \n",
    "    for _ in range(B):\n",
    "        idx = rng.choice(n, n, replace=True)\n",
    "        Y_ = Y.iloc[idx]\n",
    "        X_ = X.iloc[idx]\n",
    "        # add constant\n",
    "        X_ = sm.add_constant(X_)\n",
    "        # sm.OLS does not automatically include an intercept term\n",
    "        value = sm.OLS(Y_, X_).fit().params.values\n",
    "        first_ += value\n",
    "        second_ += value * value\n",
    "    \n",
    "    return np.sqrt(second_ / B - (first_ / B)**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "5a2161c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.85785417, 0.00745836])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "boot_OLS(Auto['horsepower'], Auto['mpg'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d61a7442",
   "metadata": {},
   "source": [
    "polynomial regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "2743a73d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def boot_polynomial_regression(X, Y, d, B=1000, seed=0):\n",
    "    # polynomial degree is d\n",
    "    rng = np.random.default_rng(seed)\n",
    "    n = X.shape[0]\n",
    "    first_, second_ = np.zeros((d+1,)), np.zeros((d+1,))\n",
    "    \n",
    "    org_Y = Y.copy()\n",
    "    org_X = X.copy()\n",
    "    org_X = np.power.outer(org_X.values, np.arange(d+1))\n",
    "    print(sm.OLS(org_Y, org_X).fit().params)\n",
    "    \n",
    "    for _ in range(B):\n",
    "        idx = rng.choice(n, n, replace=True)\n",
    "        Y_ = Y.iloc[idx]\n",
    "        X_ = X.iloc[idx]\n",
    "        # construct polynomials of X\n",
    "        X_ = np.power.outer(X_.values, np.arange(d+1))\n",
    "        value = sm.OLS(Y_, X_).fit().params.values\n",
    "        first_ += value\n",
    "        second_ += value * value\n",
    "        \n",
    "        \n",
    "    return np.sqrt(second_ / B - (first_ / B)**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "98a62cd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "const    39.935861\n",
      "x1       -0.157845\n",
      "dtype: float64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.85785417, 0.00745836])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# polynomial degree is 1\n",
    "boot_polynomial_regression(Auto['horsepower'], Auto['mpg'], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "05ff826d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "const    56.900100\n",
      "x1       -0.466190\n",
      "x2        0.001231\n",
      "dtype: float64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([2.06783958e+00, 3.30188774e-02, 1.19712226e-04])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "boot_polynomial_regression(Auto['horsepower'], Auto['mpg'], 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daad55c8",
   "metadata": {},
   "source": [
    "**Exercise**: Use bootstrap to compute the mean of mpg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "be1b3a9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def boot_mean(X, B=1000, seed=0):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9ea1d94f",
   "metadata": {},
   "outputs": [],
   "source": [
    "boot_mean(Auto['mpg'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0a12bd78",
   "metadata": {},
   "outputs": [],
   "source": [
    "boot_mean(Auto['horsepower'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d5a3bfe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
